{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "049184d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = './dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12e7d78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '5'\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append('/mnt/mhjc/RS/ogblsc/ogb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21cff504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('O=C1C=CC(O1)C(c1ccccc1C)O', 5.292614392225)\n"
     ]
    }
   ],
   "source": [
    "from ogb.lsc import PCQM4MDataset\n",
    "dataset = PCQM4MDataset(only_smiles = True)\n",
    "\n",
    "# get i-th molecule and its target value (nan for test data)\n",
    "i = 1234\n",
    "print(dataset[i]) # ('O=C1C=CC(O1)C(c1ccccc1C)O', 5.292614392225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c328bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ogb.utils import smiles2graph\n",
    "\n",
    "# smiles2graph takes a SMILES string as input and returns a graph object\n",
    "# requires rdkit to be installed.\n",
    "# You can write your own smiles2graph\n",
    "graph_obj = smiles2graph('O=C1C=CC(O1)C(c1ccccc1C)O')\n",
    "\n",
    "# convert each SMILES string into a molecular graph object by calling smiles2graph\n",
    "# This takes a while (a few hours) for the first run\n",
    "dataset = PCQM4MDataset(smiles2graph = smiles2graph)\n",
    "\n",
    "# get i-th molecule and its target value (nan for test data)\n",
    "i = 1234\n",
    "print(dataset[i]) # (graph_obj, 5.292614392225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a81d5129",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dict = dataset.get_idx_split()\n",
    "train_idx = split_dict['train'] # numpy array storing indices of training paper nodes\n",
    "valid_idx = split_dict['valid'] # numpy array storing indices of validation paper nodes\n",
    "test_idx = split_dict['test'] # numpy array storing indices of testing paper nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf52757",
   "metadata": {},
   "source": [
    "import os.path as osp\n",
    "from dgl.data.utils import load_graphs, save_graphs, Subset\n",
    "folder = 'dataset/pcqm4m_kddcup2021'\n",
    "processed_dir = osp.join(folder, 'processed')\n",
    "pre_processed_file_path = osp.join(processed_dir, 'dgl_data_processed')\n",
    "graphs, label_dict = load_graphs(pre_processed_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85044072",
   "metadata": {},
   "source": [
    "graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f8810a",
   "metadata": {},
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8ea1d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.utils import smiles2graph\n",
    "\n",
    "# if you use DGL (requires dgl to be installed) \n",
    "from ogb.lsc import DglPCQM4MDataset\n",
    "dgl_dataset = DglPCQM4MDataset(root = ROOT, smiles2graph = smiles2graph) # load all of graphs list\n",
    "\n",
    "# dgl_dataset2 = DglPCQM4MDataset(root = ROOT, smiles2graph = smiles2graph, idx_list = [ int(i) for i in train_idx] ) # load subset of graphs list => 전체 load 하는것과 비슷하게 오래걸린다.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004a28de",
   "metadata": {
    "tags": []
   },
   "source": [
    "dgl_dataset[100][0].ndata['feat'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92421ded",
   "metadata": {},
   "source": [
    "from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder\n",
    "atom_encoder = AtomEncoder(emb_dim = 100) # Pytorch Module class w/ learnable parameters\n",
    "bond_encoder = BondEncoder(emb_dim = 100) # Pytorch Module class w/ learnable parameters\n",
    "\n",
    "atom_emb = atom_encoder(dgl_dataset[0][0].ndata['feat']) # node_feat is input atom feature in Pytorch Tensor\n",
    "edge_emb = bond_encoder(dgl_dataset[0][0].edata['feat']) # edge_feat is input edge feature in Pytorch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7faebfe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3803453"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dgl_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa1639db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.dataloading import GraphDataLoader\n",
    "dataloader = GraphDataLoader(\n",
    "    dgl_dataset,\n",
    "    batch_size=1024*16,\n",
    "    drop_last=False,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3daf635",
   "metadata": {},
   "source": [
    "batched_graph, labels = dataloader.__iter__().__next__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69361d66",
   "metadata": {},
   "source": [
    "transferer = dgl.dataloading.AsyncTransferer(torch.device('cuda:1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc87f26",
   "metadata": {},
   "source": [
    "from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder\n",
    "atom_encoder = AtomEncoder(emb_dim = 100).to('cuda:1')\n",
    "\n",
    "feats = batched_graph.ndata['feat']\n",
    "feats = atom_encoder(feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6778918d",
   "metadata": {},
   "source": [
    "model = Regressor(in_dim = 100, \n",
    "                  hidden_dim = 24).to('cuda:1')\n",
    "\n",
    "logits = model(batched_graph.to('cuda:1'), feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fac9045",
   "metadata": {},
   "source": [
    "loss = F.mse_loss(logits, labels.to('cuda:1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feef50a4",
   "metadata": {},
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70d4f2b",
   "metadata": {},
   "source": [
    "labels.to('cuda:1').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918f2b28",
   "metadata": {},
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64ec8f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder\n",
    "import dgl\n",
    "\n",
    "def train(dataloader, model, atom_encoder = AtomEncoder(emb_dim = 100),\n",
    "    bond_encoder = BondEncoder(emb_dim = 100), max_iter = 5, verbose = 1, lr = 1e-3):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    transferer = dgl.dataloading.AsyncTransferer(torch.device('cuda:0'))\n",
    "   \n",
    "    for e in range(max_iter):\n",
    "        count = 0\n",
    "        for batched_graph, labels in dataloader:\n",
    "            feats = batched_graph.ndata['feat']\n",
    "#             feats = atom_encoder(feats) #.to('cuda:0')\n",
    "            feats_gpu = transferer.async_copy( feats, torch.device('cuda:0'))\n",
    "#             batched_graph_gpu = transferer.async_copy( batched_graph, torch.device('cuda:0'))\n",
    "            labels_gpu = transferer.async_copy( labels.reshape([-1,1]), torch.device('cuda:0'))\n",
    "\n",
    "            # Forward\n",
    "            logits = model(batched_graph.to('cuda:0'), feats_gpu.wait()) \n",
    "            \n",
    "            # Compute loss\n",
    "            loss = F.mse_loss(logits, labels_gpu.wait()) #.to('cuda:0')\n",
    "            if count % 32 == 0:\n",
    "                print('In count {}, loss: {:.3f}'.format(count, loss) )\n",
    "            count += 1\n",
    "            \n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()  \n",
    "\n",
    "        if e % verbose == 0:\n",
    "            print('In epoch {}, loss: {:.3f}'.format(e, loss))\n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4863cb3",
   "metadata": {},
   "source": [
    "async_copy [doc link](https://docs.dgl.ai/_modules/dgl/dataloading/async_transferer.html#AsyncTransferer)\n",
    "AsyncTransferer [doc link](https://docs.dgl.ai/api/python/dgl.dataloading.html?highlight=asynctransferer#dgl.dataloading.AsyncTransferer)\n",
    "\n",
    "GraphCollator [source link](https://docs.dgl.ai/_modules/dgl/dataloading/dataloader.html#GraphCollator)\n",
    "GraphDataLoader [source link](https://docs.dgl.ai/_modules/dgl/dataloading/pytorch.html#GraphDataLoader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33eb44ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "import dgl.nn.pytorch as dglnn\n",
    "import dgl\n",
    "\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim):\n",
    "        super(Regressor, self).__init__()\n",
    "        self.conv1 = dglnn.GraphConv(in_dim, hidden_dim, allow_zero_in_degree = True)\n",
    "        self.conv2 = dglnn.GraphConv(hidden_dim, hidden_dim, allow_zero_in_degree = True)\n",
    "        self.regress = nn.Linear(hidden_dim, 1)\n",
    "        self.atom_encoder = AtomEncoder(emb_dim = in_dim).to(torch.device('cuda:0'))\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        # Apply graph convolution and activation.        \n",
    "        h = self.atom_encoder(h)\n",
    "        h = F.relu(self.conv1(g, h))\n",
    "        h = F.relu(self.conv2(g, h))\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            # Calculate graph representation by average readout.\n",
    "            hg = dgl.mean_nodes(g, 'h')\n",
    "            return self.regress(hg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b19c9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model\n",
    "# del dataloader\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a45a4301",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In count 0, loss: nan\n",
      "In count 32, loss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2143ba508a0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m model = Regressor(in_dim = 50, \n\u001b[1;32m      4\u001b[0m                   hidden_dim = 24).to('cuda:0')\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matom_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAtomEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#.to('cuda:0')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-3ea296fd43f8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, atom_encoder, bond_encoder, max_iter, verbose, lr)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatched_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatched_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#             feats = atom_encoder(feats) #.to('cuda:0')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ogblsc/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ogblsc/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ogblsc/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/ogblsc/lib/python3.7/site-packages/dgl/dataloading/dataloader.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    799\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ogblsc/lib/python3.7/site-packages/dgl/dataloading/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    799\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ogblsc/lib/python3.7/site-packages/dgl/dataloading/dataloader.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0melem_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDGLGraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m             \u001b[0mbatched_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mbatched_graphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ogblsc/lib/python3.7/site-packages/dgl/batch.py\u001b[0m in \u001b[0;36mbatch\u001b[0;34m(graphs, ndata, edata, node_attrs, edge_attrs)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mbne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0metype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mbne\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_num_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0mretg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_batch_num_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbne\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ogblsc/lib/python3.7/site-packages/dgl/batch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mbne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0metype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mbne\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_num_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0mretg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_batch_num_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbne\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ogblsc/lib/python3.7/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36mbatch_num_edges\u001b[0;34m(self, etype)\u001b[0m\n\u001b[1;32m   1423\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_num_edges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mty\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonical_etypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m                 \u001b[0mbne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_num_edges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mty\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbne\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0metype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ogblsc/lib/python3.7/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36mdevice\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5135\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mcase\u001b[0m \u001b[0mof\u001b[0m \u001b[0mheterogeneous\u001b[0m \u001b[0mgraphs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5136\u001b[0m         \"\"\"\n\u001b[0;32m-> 5137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_backend_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=invalid-name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder\n",
    "\n",
    "model = Regressor(in_dim = 50, \n",
    "                  hidden_dim = 24).to('cuda:0')\n",
    "train(dataloader, model, atom_encoder = AtomEncoder(emb_dim = 50)) #.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ca1468d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "DGLError",
     "evalue": "[06:01:15] /opt/dgl/src/runtime/cuda/cuda_device_api.cc:196: Check failed: e == cudaSuccess || e == cudaErrorCudartUnloading: CUDA: an illegal memory access was encountered\nStack trace:\n  [bt] (0) /mnt/mhjc/miniconda3/envs/ogblsc/lib/python3.7/site-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x4f) [0x7f0979b9a01f]\n  [bt] (1) /mnt/mhjc/miniconda3/envs/ogblsc/lib/python3.7/site-packages/dgl/libdgl.so(dgl::runtime::CUDADeviceAPI::CopyDataFromTo(void const*, unsigned long, void*, unsigned long, unsigned long, DLContext, DLContext, DLDataType, void*)+0x7b) [0x7f097a3feaeb]\n  [bt] (2) /mnt/mhjc/miniconda3/envs/ogblsc/lib/python3.7/site-packages/dgl/libdgl.so(dgl::runtime::NDArray::CopyFromTo(DLTensor*, DLTensor*, void*)+0x267) [0x7f097a2ba647]\n  [bt] (3) /mnt/mhjc/miniconda3/envs/ogblsc/lib/python3.7/site-packages/dgl/libdgl.so(dgl::runtime::NDArray::CopyTo(DLContext const&) const+0xee) [0x7f097a2f158e]\n  [bt] (4) /mnt/mhjc/miniconda3/envs/ogblsc/lib/python3.7/site-packages/dgl/libdgl.so(dgl::UnitGraph::CSR::CopyTo(DLContext const&) const+0x289) [0x7f097a3df069]\n  [bt] (5) /mnt/mhjc/miniconda3/envs/ogblsc/lib/python3.7/site-packages/dgl/libdgl.so(dgl::UnitGraph::CopyTo(std::shared_ptr<dgl::BaseHeteroGraph>, DLContext const&)+0x9f) [0x7f097a3d136f]\n  [bt] (6) /mnt/mhjc/miniconda3/envs/ogblsc/lib/python3.7/site-packages/dgl/libdgl.so(dgl::HeteroGraph::CopyTo(std::shared_ptr<dgl::BaseHeteroGraph>, DLContext const&)+0xf5) [0x7f097a302785]\n  [bt] (7) /mnt/mhjc/miniconda3/envs/ogblsc/lib/python3.7/site-packages/dgl/libdgl.so(+0xcc081b) [0x7f097a30f81b]\n  [bt] (8) /mnt/mhjc/miniconda3/envs/ogblsc/lib/python3.7/site-packages/dgl/libdgl.so(DGLFuncCall+0x48) [0x7f097a29e228]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-0c529bcb7c57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0matom_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAtomEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matom_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdgl_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/ogblsc/lib/python3.7/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, device, **kwargs)\u001b[0m\n\u001b[1;32m   5190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5191\u001b[0m         \u001b[0;31m# 1. Copy graph structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5192\u001b[0;31m         \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dgl_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5194\u001b[0m         \u001b[0;31m# 2. Copy features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ogblsc/lib/python3.7/site-packages/dgl/heterograph_index.py\u001b[0m in \u001b[0;36mcopy_to\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_CAPI_DGLHeteroCopyTo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshared_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'coo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mdgl/_ffi/_cython/./function.pxi\u001b[0m in \u001b[0;36mdgl._ffi._cy3.core.FunctionBase.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mdgl/_ffi/_cython/./function.pxi\u001b[0m in \u001b[0;36mdgl._ffi._cy3.core.FuncCall\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mdgl/_ffi/_cython/./function.pxi\u001b[0m in \u001b[0;36mdgl._ffi._cy3.core.FuncCall3\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mdgl/_ffi/_cython/./base.pxi\u001b[0m in \u001b[0;36mdgl._ffi._cy3.core.CALL\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDGLError\u001b[0m: [06:01:15] /opt/dgl/src/runtime/cuda/cuda_device_api.cc:196: Check failed: e == cudaSuccess || e == cudaErrorCudartUnloading: CUDA: an illegal memory access was encountered\nStack trace:\n  [bt] (0) /mnt/mhjc/miniconda3/envs/ogblsc/lib/python3.7/site-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x4f) [0x7f0979b9a01f]\n  [bt] (1) /mnt/mhjc/miniconda3/envs/ogblsc/lib/python3.7/site-packages/dgl/libdgl.so(dgl::runtime::CUDADeviceAPI::CopyDataFromTo(void const*, unsigned long, void*, unsigned long, unsigned long, DLContext, DLContext, DLDataType, void*)+0x7b) [0x7f097a3feaeb]\n  [bt] (2) /mnt/mhjc/miniconda3/envs/ogblsc/lib/python3.7/site-packages/dgl/libdgl.so(dgl::runtime::NDArray::CopyFromTo(DLTensor*, DLTensor*, void*)+0x267) [0x7f097a2ba647]\n  [bt] (3) /mnt/mhjc/miniconda3/envs/ogblsc/lib/python3.7/site-packages/dgl/libdgl.so(dgl::runtime::NDArray::CopyTo(DLContext const&) const+0xee) [0x7f097a2f158e]\n  [bt] (4) /mnt/mhjc/miniconda3/envs/ogblsc/lib/python3.7/site-packages/dgl/libdgl.so(dgl::UnitGraph::CSR::CopyTo(DLContext const&) const+0x289) [0x7f097a3df069]\n  [bt] (5) /mnt/mhjc/miniconda3/envs/ogblsc/lib/python3.7/site-packages/dgl/libdgl.so(dgl::UnitGraph::CopyTo(std::shared_ptr<dgl::BaseHeteroGraph>, DLContext const&)+0x9f) [0x7f097a3d136f]\n  [bt] (6) /mnt/mhjc/miniconda3/envs/ogblsc/lib/python3.7/site-packages/dgl/libdgl.so(dgl::HeteroGraph::CopyTo(std::shared_ptr<dgl::BaseHeteroGraph>, DLContext const&)+0xf5) [0x7f097a302785]\n  [bt] (7) /mnt/mhjc/miniconda3/envs/ogblsc/lib/python3.7/site-packages/dgl/libdgl.so(+0xcc081b) [0x7f097a30f81b]\n  [bt] (8) /mnt/mhjc/miniconda3/envs/ogblsc/lib/python3.7/site-packages/dgl/libdgl.so(DGLFuncCall+0x48) [0x7f097a29e228]\n\n"
     ]
    }
   ],
   "source": [
    "atom_encoder = AtomEncoder(emb_dim = 50)\n",
    "graph = dgl_dataset[0][0]\n",
    "feats = atom_encoder(graph.ndata['feat'])\n",
    "model(graph.to('cuda:0'), feats.to('cuda:0') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e5ff4a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Graph(num_nodes=18, num_edges=40,\n",
      "      ndata_schemes={'feat': Scheme(shape=(9,), dtype=torch.int64)}\n",
      "      edata_schemes={'feat': Scheme(shape=(3,), dtype=torch.int64)}), tensor(3.0477))\n"
     ]
    }
   ],
   "source": [
    "print(dgl_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b89fdc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Cc1ccc(cc1)C1C=c2cnccc2=NC1=O', 3.0476751256)\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
